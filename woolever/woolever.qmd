---
title: "Collecting Concurrent Validity, Expert-Rater Agreement, and Inter/Intra-Rater Reliability for the FG-COMPASS"
# Lines above title in .docx format
blank-lines-above-title: 2
# If blank, the running header is the title in upper case.
shorttitle: Validity and reliability of a test
# Set names and affiliations.
# It is nice to specify everyone's orcid, if possible.
# There can be only one corresponding author.
author:
  - name: Mackinsey Woolever
    corresponding: false
    orcid: 0000-0000-0000-0000
    affiliations:
      - id: id1
        name: California State University, Northridge
        department: Department of Kinesiology
  - name: Ovande Furtado Jr
    corresponding: true
    orcid: 0000-0003-3847-6314 
    email: ovande@gmail.com (818-564-7507)
    affiliations: 
    - name: California State University, Northridge
      department: Department of Kinesiology
      address: 18111 Nordhoff St
      city: Northridge
      region: CA
      postal-code: 91330-8287
  - name: Jere D. Gallagher
    corresponding: false
    affiliations: 
    - name: University of Pittsburgh
author-note:
  blank-lines-above-author-note: 1
  status-changes: 
    # Example: [Author name] is now at [affiliation].
   # affiliation-change: Ana Fulana is now at X University.
    # Example: [Author name] is deceased.
    deceased: Jere D. Gallagher is deceased.
  # Disclosures condensed to one paragraph, but you can start a field with two line breaks to break them up: \n\nNew Paragraph
  disclosures:
    # Example: This study was registered at ClinicalTrials.gov (Identifier NTC998877).
    study-registration: ~
    # Acknowledge and cite data/materials to be shared.
    data-sharing: ~
    # Example: This article is based on data published in Pulaski (2017).
    # Example: This article is based on the dissertation completed by Graham (2018).    
    #related-report: This article is based on data published in Pulaski (2017). 
    # Example: Sally Jones earns royalties from the sale of Test X.
    conflict-of-interest: ~
    # Example: This study was supported by Grant A123 from the National Science Foundation.
    financial-support: ~
    # Example: The authors are grateful for the technical assistance of Dr. X during the initial design and setup of our lab equipment.
    gratitude: ~
    # Example. Because the authors are equal contributors, order of authorship was determined by a fair coin toss.
    authorship-agreements: ~
abstract: "Fundamental movement skills (FMS) are the building blocks for developing specialized sports skills. In addition, fundamental movement skill competency has been linked to decreased levels of obesity and increased levels of physical activity/sports participation. This study aimed to collect evidence for concurrent validity, inter-intra-, and expert-rater reliability for the FG-COMPASS. Participants were 34 children ages 5-10 years. The agreement between the FG-COMPASS and TGMD-2 was evaluated using the intraclass correlation coefficient (ICC) and Bland-Altman analysis for LFMS, MFMS, and TFMS. The ICC for the LFMS subtest was .68, indicating a 'good' agreement between the two tests. The Bland-Altman analysis revealed a mean bias close to zero. 'Excellent' agreement was observed for the MFMS subtest, with an ICC of .89 and Bland-Altman bias close to zero. The TFMS also demonstrated 'excellent' agreement, with an ICC of .89 and Bland-Altman bias close to zero. The inter-rater reliability of the FG-COMPASS was assessed by comparing the live scores of all five raters involved in the study. Weighted kappa values ranged from .42 to .93 (M = .66, SD = .15) for the LFMS subtest and from .31 to .93 (M = .77, SD = .15) for the MFMS subtest. The test's combined score (TFMS) was .72 (SD = .15). The resulting weighted kappa indicates 'good' agreement for the LFMS, MFMS subtests, and the total test (TFMS). The weighted kappa results for the intra-rater reliability indicate a ‘good’ agreement for LFMS (.69), MFMS (.70), and TFMS (.70). The agreement between raters and the expert indicates a 'good' agreement for LFMS (.64), MFMS (.75), and TFMS (.70). This study shows that the FG-COMPASS is a reliable and effective tool for assessing motor skills. Future research should focus on exploring any minor differences in the locomotor subtest and understanding the variations in rater interpretations. Additionally, adding two more skills to the locomotor subtest would be beneficial."
keywords: [Assessment, Fundamental Movement Skills, Children, Movement Competence, Rating Scales, Assessment, Reliability, Agreement, Concurrent Validity]
# I like using Zotero with BetterBibTeX to output a continuously updated "Better CSL JSON" file. But BibTeX works, too.
bibliography: bibliography.bib
format:
  apaquarto-docx: default
  apaquarto-html: default
  apaquarto-pdf:
    # can be jou (journal), man (manuscript), stu (student), or doc (document)
    # for now, tables and figures do not render properly in jou mode. 
    documentmode: man
    # can be 10pt, 11pt, or 12pt
    fontsize: 12pt
    # Integrate tables and figures in text
    floatsintext: false
    # a4 paper if true, letter size if false
    a4paper: false
    # suppresses loading of the lmodern font package
    nolmodern: false
    # Suppresses loading of the fontenc package
    nofontenc: false
    # Suppress the title above the introduction
    donotrepeattitle: false
    # In jou mode, use times or pslatex instead of txfonts
    notxfonts: false
    # In jou mode, use Computer Modern font instead of times
    notimes: false
    # In jou mode, cancels automatic stretching of tables to column width 
    notab: false
    # Uses Helvetica font in stu and man mode
    helv: false
    # In man and stu mode, neutralizes the \helvetica command.
    nosf: false
    # In man and stu mode, uses typewriter font
    tt: false
    # Puts draft watermark on first page
    draftfirst: false
    # Puts draft watermakr on all pages
    draftall: false
    # Masks references that are marked as the author's own
    mask: false
    journal: ~
    volume: ~
    course: ~
    professor: ~
    duedate: ~
---

```{r}
#| label: setup
library(conflicted)
library(tidyverse)
library(flextable)
library(ftExtra)
library(officer)
library(knitr)
conflicts_prefer(dplyr::filter, .quiet = TRUE)
conflicts_prefer(flextable::separate_header, .quiet = TRUE)
```

# Introduction

The acquisition of locomotor (e.g., hop, skip, jump) and manipulative (e.g., throw, kick, catch) fundamental movement skills (FMS) is critically important for young children, as it can significantly influence their development and lifestyle. Motor competence plays a pivotal role in an individual's participation in physical activities [@castelli2007]. Studies have shown a favorable correlation between perceived motor competence and proficiency in FMS among children and adolescents [@woods2007]. Engagement in physical activity and the development of FMS are positively correlated, particularly when the activities are of moderate to vigorous intensity [@bellows2013; @fisher2005; @lemos2012; @mckenzie2002]. Moreover, there is an inverse relationship between physical activity involvement and the prevalence of obesity [@bayer2009; @graf2004; @lopes2012]. Inadequate motor skill competence in children is correlated with reduced physical activity levels [@fisher2005; @mckenzie2002] and an increased likelihood of being overweight or obese [@cliff2012].

Therefore, assessing the development of FMS is crucial for preschool and primary school children, as these skills significantly influence their overall development and well-being. According to @ulrich2000, early childhood education often neglects the development of FMS. Assessment instruments are developed to identify variations in motor development, ranging from minor to significant delays. Failure to promptly address delays in motor skill development may hinder the subsequent development of FMS [@ulrich2000] and subsequentely affect the acquisition of specialized skills [@gabbard2021].

As noted by @provost2000, a developmental delay is defined as a discrepancy of 25% or greater between a child's chronological age and developmental age. Early detection of motor delays enables practitioners, parents, and educators to implement effective intervention measures. Various instruments exist for assessing FMS, as highlighted by @cools2009. However, many of these tools are not designed for live assessment by a single practitioner, typically requiring performance recording and later evaluation. Developing an assessment tool that allows professionals to assess children's FMS proficiency in real-time without performance recording would enhance convenience and efficiency.

The Furtado-Gallagher Children Observational Movement Pattern Assessment System (FG-COMPASS) [@furtado2012] was developed to fill this gap and address the need for a practical assessment tool to evaluate FMS development in school-age children. To date, no studies have compared the results of the FG-COMPASS with those of a criterion measure. Although the FG-COMPASS has demonstrated evidence of both inter- and intra-rater reliability, the agreement data used in these studies were obtained through video analysis rather than live performances [@furtado2012; @furtado2018].

Collecting psychometric data on live performance is crucial, as the FG-COMPASS is intended for use in real-time settings without the need for video recording. Therefore, this study aimed to establish criterion-related (concurrent) validity for the FG-COMPASS by comparing its results with the TGMD-2 [@ulrich2000], a popular instrument for assessing FMS in children. Additionally, this study sought to gather further evidence of inter-, intra-, and expert-rater[^1] reliability for the FG-COMPASS through live assessments.

[^1]: The co-author of the FG-COMPASS served as the expert in this study.

Several hypotheses were proposed for this study. We anticipated that there would be at least a 'good' agreement (ICC/kappa scores above .74) for the locomotor (LFMS), manipulative (MFMS), and total test (TFMS) components when investigating concurrent validity, inter- and intra-rater reliability, and expert-rater reliability for the FG-COMPASS.

# Materials and Methods

## Participants

A convenient sampling method was employed to recruit participants for this study. Following Institutional Review Board approval from (XXXXXXX), 41 children between the ages of 5 and 10 were initially recruited. Ultimately, 34 children, comprising 22 girls (*M* = 8.14, *SD* = 1.78) and 12 boys (*M* = 8.44, *SD* = 1.49), fully participated. Three participants independently withdrew from the study; two did not attend the assessment sessions, one was injured prior to the assessment, and one child relocated out of state during the data collection period. Informed consent was obtained from the parents or legal guardians of all participants prior to their involvement in the study and the children assent to participate. <!--# see Lino's study on how to phrase this -->

To ensure an even distribution of age ranges, one randomly selected classroom from kindergarten through fourth grade received a recruitment packet. If no consent forms were returned, recruitment packets were distributed to additional classrooms. Participants were excluded from the study if they met any of the following criteria: 1) younger than five years or older than 10 years and 11 months; 2) had developmental delays or disabilities that could affect motor performance; 3) lacked parental or verbal consent <!--# what is verbal consent? -->; or 4) had a "yes" response on any of the first five Physical Activity Readiness-Questionnaire (PAR-Q) questions [@adams1999].

## Measures

### TGMD-2

The TGMD-2 [@ulrich2000] served as the gold standard (criterion measurement) for the concurrent validity analysis. It evaluates twelve FMS, divided into two categories: six concerning locomotion and six related to object manipulation, suitable for children aged 3 to 10 years. The TGMD-2 assesses various performance criteria focusing on different body components, including the arms, legs, and trunk. For example, one criterion for hopping is that the "arms be flexed and swing forward to generate force." Each child is given two attempts to demonstrate each skill; successful attempts are awarded a score of 1, while unsuccessful attempts receive a score of zero. After two trials for each skill, the scores are totaled to obtain the overall raw score for each subtest. These raw scores are then converted to standard scores, enabling comparison to normative data. Researchers can determine age equivalents and percentiles by analyzing the standard scores from both subtests. These standard scores, when combined, form a gross motor quotient value [@ulrich2000].

Several studies have addressed the validity and reliability of the TGMD-2. The instrument demonstrates strong construct validity, effectively measuring the fundamental theoretical construct of gross motor development [@ulrich2000]. Its concurrent validity is supported through correlations with other established motor skill assessments, such as the Movement Assessment Battery for Children (MABC) [@cools2009]. High test-retest reliability of the TGMD-2 has been reported, with coefficients frequently exceeding .90 [@valentini2004]. The test maintains good internal consistency, evidenced by Cronbach's alpha values generally above .80 for both the locomotion and object manipulation subtests [@wiart2001]. The TGMD-2 has also been adapted and validated in different cultural contexts, indicating its utility across various populations [@barnett2009]. The standardization process involved a representative sample of children in the United States, ensuring the relevance of the normative data for the target age group.

### FG-COMPASS

The FG-COMPASS comprises of eight FMS rating scales divided into a locomotor (hop, horizontal jump, skip) and a manipulative subtest (throw, kick, hand dribble, strike, catch) [@furtado2012].

The test was developed to be used in live settings and address the need for a practical assessment tool to evaluate FMS development in school-age children. This is possible because the test assess FMS proficiency by having motor skill performance criteria placed into rating scales in the form of a decision tree. This novel approach, detailed further in works by @perez2018 and @furtado2012, utilizes key performance criteria arranged in a decision tree to create FMS rating scales. An example of a performance criteria for the skill of throw is: *Rotation of the trunk to the side of the throw during preparation.* Figure 2 depicts the decision tree for the 'Overhand Throw' skill, demonstrating three types of nodes: decision nodes, which pose questions; chance nodes, offering 'yes or no' options; and end nodes, which indicate proficiency levels.

These trees are formed through questions derived from the criteria. For instance, in Figure 1, a question at the top decision node aims to differentiate between levels 1 and 4. A 'yes' at the chance node directs to the right pathway, prompting a follow-up question to confirm if the individual exhibits a level 4 proficiency in overhand throws. If the answer is 'no,' the rating settles at level 3.

A similar process occurs on the left side of the tree to assess for level 1 proficiency. This approach allows for a simplified evaluation of live performances of FMS, restricting the assessment to just two performance criteria when determining skill proficiency levels. The FG-COMPASS enjoys support from several studies validating its efficacy and reliability, including evidence for content-related validity [@furtado2004], expert-rater agreement [@furtado2012; @furtado2018], and intra- and inter-rater reliability [@furtado2018] from video performances.

\[figure 1 here\] <!--# add the new decision tree here -->

## Research Assistants

Sixteen undergraduate kinesiology students were selected as research assistants for this study. Ten students were chosen to serve as raters in the assessment of FMS, with a random assignment of five raters per instrument: TGMD-2 and FG-COMPASS. The remaining students were assigned roles as test administrators—three for TGMD-2 and two for FG-COMPASS—except for one individual assigned to edit videos remotely, thus not requiring presence at the research site.

Before initiating data collection, all participants underwent training tailored to their designated roles and respective instruments. The training involved multiple sessions designed to equip them with the necessary skills, including instruction on setting up for skills assessment, accurately demonstrating tasks, and appropriately using and positioning cameras for recording. This comprehensive training ensured that both raters and test administrators were well-prepared to carry out their tasks effectively during the data collection phase.

<!--# CONTINUE FROM HERE.... -->

## Procedures

### Data collection

The TGMD-2 and the FG-COMPASS, while assessing the same construct, differ in their evaluation methods. Despite these differences, common procedures were followed in administering both tests. The assessments were conducted during morning or lunch recess periods to ensure all student participants could complete both tests.

Before data collection began, the primary investigator assigned identification numbers to the participants to maintain organization. Upon arrival at the test location, participants were guided to either the TGMD-2 or FG-COMPASS stations according to a randomized list. This setup was revisited weekly to mitigate potential learning effects from repeated measurements of the same skill. After completing the initial test at one station, participants moved to the alternate station for further assessment. In some cases, participants demonstrated multiple skills across both stations, alternating between them as needed.

The administrators overseeing the TGMD-2 station conducted assessments weekly, following the directives detailed in the user manual by @ulrich200. All skill performances were videotaped, and TGMD-2 raters later assessed the performances in the lab using the recorded videos. The FG-COMPASS raters evaluated participants directly on-site, although these performances were also recorded for intra-rater reliability analysis. Participants were provided one practice trial and three test trials for each skill.

## Data Analysis

Concurrent validity was assessed using the intraclass correlation coefficient (ICC, 2, k) and Bland-Altman plots. The reliability of the FG-COMPASS, both in terms of inter- and intra-rater consistency and the agreement between the expert and raters, was examined using weighted kappa statistics.

The ICC is designed to evaluate the reliability of ratings by comparing the variation of different ratings for the same participant to the total variation across all ratings and participants [@mcgraw1996]. The Bland-Altman method involves determining the agreement between two quantitative measurements by studying the average difference and setting agreement limits, a strategy preferred over correlation techniques [@bland1986; @giavarina2015].

The weighted kappa index is recommended when more than two coders independently classify an entity into three or more categories at an ordinal level, assigning different weights based on the degree of disagreement [@fleiss1973]. Unlike kappa, the weighted version considers the degree of disagreement in its calculation. The interpretation of weighted kappa and ICC values followed this scheme: above .75 indicated excellent agreement; values between .74 and .60 were good; values between .59 and .40 were fair, and values below .40 were poor [@cicchetti1994].

A cross-sectional design was utilized in this study, and all statistical analyses were conducted using the statistical package jamovi [@jamovi233]. <!--# consider SPSS here -->

# Results

## Concurrent Validity

The agreement between the FG-COMPASS and TGMD-2 was evaluated using the intraclass correlation coefficient (ICC) and Bland-Altman analysis for the locomotor (LFMS), manipulative (MFMS), and total fundamental movement skills (TFMS) subtests (see {apatb-table1}). The ICC for the LFMS subtest was .68, indicating 'good' agreement between the two tests. The Bland-Altman analysis for the LFMS subtest revealed a mean bias close to zero (see Figure 2). The MFMS subtest exhibited 'excellent' agreement, with an ICC of .89 and Bland-Altman bias also close to zero (see Figure 3). Similarly, the TFMS subtest demonstrated 'excellent' agreement, with an ICC of .89 and Bland-Altman bias close to zero (see Figure 4).

```{asis}
#| label: apatb-table1
#| apa-cap: Concurrent Validity Analysis for FG-COMPASS
#| apa-note: ICC:\ Intraclass Correlation Coefficient (ICC, 2, k). Bias:\ Mean difference between the two methods. LLA & ULA:\ 95% lower and upper limits of agreement in the Bland-Altman analysis.<br/> (*):\ _p_ < .05.<br/> (**):\ _p_ < .001.
#| echo: true
|                  | _ICC_       | _F_ (p-value) | Bias       | LLA       | ULA       |
|------------------|-----------|-----------------------|------------|-----------|-----------|
| **Locomotor**    | .68      | 3.05 (*)              | 1.73e−16   | −1.95     | 1.95      |
| **Manipulative** | .89      | 8.85 (**)             | 2.60e−16   | −1.25     | 1.25      |
| **Total test**   | .89      | 9.00 (**)             | −2.53e−16  | −1.24     | 1.24      |
```

\[figure 2 here\] \[figure 3 here\] \[figure 4 here\]

## Inter-Rater Reliability

The inter-rater reliability of the FG-COMPASS was assessed by comparing the live scores of all five raters involved in the study (see {apatb-table2}). Weighted kappa values were computed for each pair of raters, and the mean was calculated to provide a single index of reliability [@light1971]. For the LFMS subtest, weighted kappa values ranged from .42 to .93 (*M* = .66, *SD* = .15). For the MFMS subtest, values ranged from .31 to .93 (*M* = .77, *SD* = .15). The combined score (TFMS) yielded a weighted kappa of .72 (*SD* = .15). These results indicate 'good' agreement for the LFMS, MFMS subtests, and the total test (TFMS).

```{asis}
#| label: apatb-table2
#| apa-cap: Weighted Kappa Statistics for the Inter-Rater Analysis
#| apa-note: LFMS:\ Locomotor Subtest. MFMS:\ Manipulative Subtest. TFMS:\ Locomotor and Manipulative scores combined. <br/> Hashtags indicate major disagreement between rater 5 and all other raters. 
#| echo: true

|               | Skill         | 1x2  | 1x3  | 1x4  | 1x5  | 2x3  | 2x4  | 2x5  | 3x4  | 3x5  | 4x5  | _Mean_ | _SD_   |
|---------------|---------------|------|------|------|------|------|------|------|------|------|------|------|------|
| **LFMS**      |               |      |      |      |      |      |      |      |      |      |      | **.66**  | .15  |
|               | Hop       | .56  | .43  | .43  | .50  | .42  | .49  | .46  | .53  | .64  | .52  | .50  | .07  |
|               | Jump        | .93  | .91  | .70  | .65  | .84  | .73  | .62  | .61  | .61  | .69  | .73  | .12  |
|               | Skip      | .78  | .74  | .60  | .63  | .87  | .77  | .76  | .69  | .71  | .83  | .74  | .08  |
| **MFMS**      |               |      |      |      |      |      |      |      |      |      |      | **.77**  | .15  |
|               | Throw       | .85  | .79  | .85  | .45^\#^ | .80  | .73  | .35^\#^ | .71  | .31^\#^ | .40^\#^ | .62  | .22  |
|               | Kick       | .83  | .68  | .64  | .82  | .63  | .59  | .73  | .50  | .72  | .64  | .68  | .10  |
|               | Dribble   | .86  | .87  | .83  | .92  | .88  | .84  | .91  | .88  | .93  | .93  | .89  | .04  |
|               | Catch      | .87  | .91  | .87  | .90  | .83  | .84  | .90  | .80  | .80  | .89  | .86  | .04  |
|               | Strike       | .81  | .80  | .72  | .72  | .87  | .80  | .80  | .69  | .78  | .79  | .78  | .05  |
| **TFMS**      |               |      |      |      |      |      |      |      |      |      |      | **.72**  | .15  |

```

## Intra-rater reliability for the FG-COMPASS

We evaluated the consistency of ratings for the FG-COMPASS by comparing live assessments with those obtained through video assessments (see {apatb-table3}). Of particular interest is 'IR1', which compares the ratings we obtained from live assessments with those from recorded performances one week later. Additionally, we included ratings from a second video assessment and compared it with the live assessment (IR2) and the first video assessment (IR3). {apatb-table4} provides the mean and standard deviation scores for each intra-rater comparison across all five raters. Scores ranged from .50 to .89, indicating agreement from 'fair' to 'excellent' [@cicchetti1994].

{{< pagebreak >}}

```{asis}
#| label: apatb-table3
#| apa-cap: Intra-Rater Agreement Measured by Weighted Kappa Coefficients Across Different Skills
#| apa-note: Quadratic weighted kappa values range from -1 to 1. IR1, IR2, and IR3 represent three different comparison pairs:\ IR1 compares the ratings from the live performances with the recorded video (time 1), IR2 compares ratings from the live performances with the recorded video (time 2), and IR3 compares the ratings from the recorded performances from time 1 and time 2. Sample sizes for each skill are provided in parentheses next to the skill name. Rater 1 to Rater 5 represents five different individuals who rated the performances.
#| echo: true

|         |        Rater 1       |        Rater 2       |        Rater 3       |        Rater 4       |        Rater 5       |
|---------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
|         |     IR1     |     IR2     |     IR3     |     IR1     |     IR2     |     IR3     |     IR1     |     IR2     |     IR3     |     IR1     |     IR2     |     IR3     |     IR1     |     IR2     |     IR3     |
| Hop (17)    |    .72     |    .83     |    .89     |    .44     |    .55     |    .75     |    .64     |    .62     |    .88     |    .69     |    .40     |    .62     |    .84     |    .62     |    .80     |
| Jump (18)   |    .56     |    .49     |    .83     |    .46     |    .68     |    .39     |    .74     |    .38     |    .49     |    .56     |    .28     |    .56     |    .67     |    .67     |    1.00     |
| Skip (18)   |    .96     |    .96     |    1.00     |    .94     |    .78     |    .86     |    .92     |    .86     |    .89     |    .51     |    .68     |    .86     |    .66     |    .52     |    .83     |
| Throw (18)  |    .80     |    .52     |    .53     |    .63     |    .62     |    .97     |    .52     |    .54     |    .60     |    .69     |    .76     |    .70     |    .54     |    .66     |    .86     |
| Kick (19)   |    .72     |    .68     |    .78     |    .66     |    .60     |    .76     |    .80     |    .70     |    .74     |    .74     |    .64     |    .72     |    .64     |    .62     |    .80     |
| Dribble (17)|    .86     |    .80     |    .82     |    .70     |    .78     |    .86     |    .66     |    .60     |    .82     |    .76     |    .68     |    .74     |    .60     |    .64     |    .68     |
| Catch (20)  |    .68     |    .62     |    .86     |    .86     |    .66     |    .80     |    .76     |    .78     |    .82     |    .66     |    .60     |    .78     |    .84     |    .88     |    .88     |
| Strike (20) |    .62     |    .56     |    .60     |    .74     |    .70     |    .70     |    .64     |    .64     |    .64     |    .74     |    .68     |    .68     |    .70     |    .62     |    .78     |


```

{{< pagebreak >}}

```{asis}
#| label: apatb-table4
#| apa-cap: Summary of Quadratic Weighted Kappa for Intra-Rater Comparisons Across Motor Skills
#| apa-note: IR1, IR2, IR3:\ Represent different inter-rater comparisons (e.g., live vs. video 1, live vs. video 2, video 1 vs. video 2). Mean:\ The average of the quadratic weighted kappa values for each scenario across all raters and skills. SD:\ The standard deviation of the quadratic weighted kappa values for each scenario across all raters and skills.
#| echo: true

| Skill   | IR1 Mean (SD) | IR2 Mean (SD) | IR3 Mean (SD) |
|---------|---------------|---------------|---------------|
| LFMS    | **.69**          | .62          | .78          |
| Hop     | .67 (.13)   | .60 (.14)   | .79 (.10)   |
| Jump    | .60 (.10)   | .50 (.16)   | .65 (.23)   |
| Skip    | .80 (.18)   | .76 (.15)   | .89 (.06)   |
| MFMS    | **.70**          | .66          | .76          |
| Throw   | .64 (.10)   | .62 (.09)   | .73 (.16)   |
| Kick    | .71 (.06)   | .65 (.04)   | .76 (.03)   |
| Dribble | .72 (.09)   | .70 (.08)   | .78 (.06)   |
| Catch   | .76 (.08)   | .71 (.11)   | .83 (.04)   |
| Strike  | .69 (.05)   | .64 (.05)   | .68 (.06)   |
| TFMS    | **.70**          | .64          | .77          |

```

## Expert-Rater Agreement for the FG-COMPASS

The study aimed to assess the level of agreement between raters and expert ratings for the FG-COMPASS. The live ratings of five raters were compared with the expert's video scores. The results showed that the level of agreement varied across the skills assessed. For 'Hop', the agreement ranged from 'fair' to 'excellent', with a mean kappa value of .67. The agreement was more varied for' Skip', with kappa values ranging from 'poor' to 'excellent'. In the MFMS subtest, the agreement was considered 'excellent'. For 'Throw', the agreement ranged from good to excellent, with a mean kappa value of .75. For 'Dribble', all raters showed 'excellent' agreement, with kappa values ranging from .77 to .94 and a mean kappa of .86. For 'Catch', the agreement was 'excellent', with a mean kappa value of .83. For 'Strike', the agreement was 'fair' to 'good' with kappa values ranging from .40 to .61 and a mean kappa of .51. Considering all skills (TFMS), the mean kappa value was .70, indicating 'good' agreement across all skills when considering all raters.

```{asis}
#| label: apatb-table5
#| apa-cap: Weighted Kappa Scores between Raters and an Expert 
#| apa-note: Kappa scores are displayed without 95% confidence intervals. The mean and SD columns represent each skill's average kappa score and dispersion, respectively. For LFMS, MFMS, and TFMS, these represent averages of the skills under each category. Sample sizes for each skill are indicated in parentheses after the skill name. 
#| echo: true

|            | Skill       | Rater 1   | Rater 2   | Rater 3   | Rater 4    | Rater 5    | Mean   | SD    |
|:-----------|:------------|:----------|:----------|:----------|:-----------|:-----------|:-------|:------|
|  LFMS      |             |           |           |           |            |            | **.64**   | .12  |
|            | Hop (17)    | .71      | .77      | .50      | .65       | .70       | .67   | .09  |
|            | Jump (18)   | .74      | .83      | .78      | .75       | .57       | .73   | .09  |
|            | Skip (18)   | .67      | .76      | .59      | .29       | .35       | .53   | .18  |
|  MFMS      |             |           |           |           |            |            | .74   | .08  |
|            | Throw (19)  | .92      | .79      | .65      | .71       | .69       | **.75**   | .10  |
|            | Kick (19)   | .82      | .70      | .51      | .78       | .82       | .73   | .12  |
|            | Dribble (17)| .91      | .77      | .94      | .77       | .89       | .86   | .07  |
|            | Catch (20)  | .89      | .84      | .83      | .82       | .76       | .83   | .04  |
|            | Strike (19) | .61      | .57      | .50      | .49       | .40       | .51   | .07  |
|  TFMS      |             |           |           |           |            |            | **.70**   | .10  |
```

# Discussion

This study aimed to establish the FG-COMPASS's concurrent validity by comparing its results to those of the TGMD-2. The study also sought further evidence of the FG-COMPASS's inter-, intra-, and expert-rater reliability.

## Concurrent Validity Between the FG-COMPASS and the TGMD-2

The concurrent validity assessment between the FG-COMPASS and the TGMD-2 provides insights into the agreement and potential discrepancies between the two tests. Establishing concurrent validity is important when testing motor skills because it shows how much a new instrument, like the FG-COMPASS, can be used in place of or with an established test, like the TGMD-2.

For the LFMS, the observed ICC of .68 falls within the 'good' range of agreement. This suggests that while both tests are aligned in their assessment of locomotor skills to a considerable extent, there are nuances or specific elements captured differently by each test. The Bland-Altman analysis further elucidates this observation. With a mean bias close to zero, there is virtually no systematic difference between the two tests regarding the locomotor subtest. The 95% limits of agreement, however, ranging from −1.95 to 1.95, show that individual scores can differ by almost two units (z-scores) in either direction. This range of disagreement suggests that, while the tests are generally aligned, they might occasionally produce different scores for the same individual.

The MFMS demonstrated a stronger alignment between the FG-COMPASS and TGMD-2, with an ICC of .89. This level of agreement underscores that both tests have a similar evaluation framework for manipulative skills. The Bland-Altman analysis further supports this, with a mean bias close to zero, indicating negligible systematic differences. The 95% limits of agreement, spanning from −1.25 to 1.25, are tighter than those of the locomotor subtest, indicating more consistent agreement between the tests for individual scores in this category. It should be noted that the FG-COMPASS has three locomotor and five manipulative skills compared to the TGMD-2, which has six skills in each subtest. This imbalance in the number of skills in the locomotor subtest between the two tests likely affected the observed difference. This can be verified in future studies since two new locomotor skills have recently been added [@perez2018] to the locomotor subtest of the FG-COMPASS.

For the TFMS, the ICC was also .89, mirroring the 'excellent' agreement observed in the manipulative subtest. The Bland-Altman analysis revealed a bias close to zero, again suggesting no meaningful systematic difference. The 95% limits of agreement ranged from −1.24 to 1.24, comparable to the manipulative subtest, showing a consistent level of individual score agreement across the entirety of the tests.

In light of these findings, the FG-COMPASS has acceptable concurrent validity with the TGMD-2, especially for assessing manipulative skills. Although there is 'good' agreement in the locomotor subtest, the results indicate that the FG-COMPASS can be reliably used in contexts where the TGMD-2 is the standard. However, practitioners should exercise caution and consider potential discrepancies, especially when assessing locomotor skills. The observed differences could be attributed to the inherent variations in test structures, scoring criteria, or specific motor skills targeted. Further investigation could explore these nuances to improve the FG-COMPASS or offer more specific direction on its use in conjunction with or instead of the TGMD-2.

## Inter-Rater Analysis

The FG-COMPASS's inter-rater reliability assessment provided insights into the agreement of different raters' ratings. The weighted kappa values showed 'good' agreement for the LFMS, 'excellent' for the MFMS subtests, and 'good' for the overall test (TFMS). The agreement for the manipulative skills (.77) was slightly higher when compared to the locomotor skills (.66) - see {apatb-table2}. This trend has been seen in previous research when measuring inter-rater reliability [@houwen2010; @valentini2012]. In addition, a previous study [@furtado2018] found similar but higher kappa scores for LFMS (.89), MFMS (.88), and TFMS (.89) when investigating the inter-rater reliability of the FG-COMPASS. These scores suggest an 'excellent' agreement. In the @furtado2018 study, raters assessed performers based on videos, whereas in the present study, we assessed live performances.

For the LFMS subtest, 'Skip' achieved the highest mean reliability (.74), followed by 'Jump' (.73), suggesting a 'good' agreement among raters for both skills. This is consistent with @furtado2018 study, in which the inter-rater reliability for 'Jump' was found to be .92. On the other hand, 'Hop' had a lower mean reliability of .50, implying more variability in raters' scores. More training on the performance criteria for 'Hop' was necessary to avoid guessing when classifying the performers. A potential misunderstanding of the criteria may also have led to guessing and poor agreement among the raters. Thirdly, borderline performances may have led to disagreement among raters. Performances from individuals who are transitioning between levels are difficult to classify. After closely examining the recorded performances, it was noted that approximately two-thirds of the performers could be considered "borderline."

Within the MFMS subtest, 'Dribble' and 'Catch' had particularly high agreement scores of .89 and .86, respectively. These values are similar to @furtado2018 study and reinforce the robustness of the scoring system for these skills. In contrast, the 'Throw' skill had an interesting result. While the kappa value (.62) was considered 'good', it had a significantly higher standard deviation (.22) than the other skills. The asterisks in the {apatb-table2} further highlight substantial disagreements between rater #5 and the other raters for this skill, suggesting potential inconsistencies or misinterpretations in the rating criteria or procedure for 'Throw'. In the current study, the weighted kappa of .62 (good) would increase to .79 (excellent) if rater #5 was removed from the analysis. Rater #5 showed the largest disagreement compared to the other four raters (see {apatb-table2}). The estimated agreement values were .45, .35, .31, and .40 between rater #5 and raters 1, 2, 3, and 4, respectively. These values are considerably lower when compared to the pair agreement values for the other raters, which ranged from .71 to .85. Such a discrepancy suggests that rater #5 misunderstood the criteria associated with 'Throw'. The kappa values for 'Kick' (.68) and 'Strike' (.78) are slightly lower when compared to the @furtado2018 study (e.g., Kick = .90, Strike = .86). The reason for the difference can be traced back to the fact that the raters in the current study evaluated performances in a live setting. In contrast, the raters in the 2018 study evaluated performances recorded on video.

The TFMS combined score reliability of .72 reflects a balanced representation of the LFMS and MFMS subtests, adding to the tool's reliability. However, it is important to address the discrepancies and variations among the raters, especially the pronounced differences with rater #5 for the skill of 'Throw'. Such discrepancies could arise from several factors, including differing interpretations of scoring criteria, rater training, or even the subjective nature of certain skills. Future attempts to collect inter-rater reliability for the FG-COMPASS should give special attention to standardizing interpretations and emphasizing areas where disagreements are most apparent.

## Intra-Rater Reliability

Evaluating intra-rater reliability is crucial for assessing the consistency of measurements taken by raters at two different times, typically one week apart. Because the FG-COMPASS is being developed to assess motor skill performance in a live setting, this study was particularly focused on how live assessments compare with video recordings of the same performance. Following the live assessment of performances, which were recorded on video, participants returned to the lab twice to re-assess the recorded performances: one week after the live performances and again two weeks after the live performances. The mean values presented in {apatb-table4} provide a comprehensive overview of each rater's consistency across the three combinations: live versus recording - time 1 (IR1), live versus recording - time 2 (IR2), and recording time 1 versus recording time 2 (IR3). Based on {apatb-table4}, the average reliability score for the IR1 comparison is a noteworthy finding. This evaluation is especially interesting because it assesses the agreement between real-time ratings and those gathered from video recordings one week after the initial assessments.

The results indicate a 'good' agreement for LFMS (.69), MFMS (.70), and TFMS (.70). Regarding individual skills, 'Skip' demonstrated a high mean kappa intra-rater reliability of .80 for IR1. This suggests an 'excellent' agreement between the live and the first video assessments for this skill. On the other hand, the skill 'Jump' had a lower mean reliability score of .60, suggesting a possible inconsistency in intra-rater reliability. The TFMS mean kappa value (.70) observed between live ratings and video recordings is considered 'good'. This value is lower than that obtained (.91) in a previous study [@furtado2018], which assessed intra-rater reliability from video recordings. This difference was expected since assessing performance from videos is less challenging compared to live assessment.

## Raters vs. Expert Agreement for the FG-COMPASS

The expert-rater agreement is the degree to which raters in this study agreed with an expert familiar with the FG-COMPASS testing protocol. Thus, one of the aims of this study was to measure the level of agreement between the ratings of five raters and the expert's video scores.

An average kappa value of .64 indicates that the agreement between the raters and the expert in the LFMS category was generally 'good'. For 'Hop', the raters' evaluations closely aligned with the expert, yielding a mean kappa value of .67. The 'Jump' skill exhibited even greater alignment between the raters and the expert, with a kappa value .73. On the other hand, the 'Skip' skill demonstrated a fair agreement level, with an average kappa value of .53. The 'Hop' and 'Jump' results indicate a shared interpretation of the evaluation criteria between the raters and the expert. The variability in kappa values for 'Skip' indicates potential differences in interpretation or understanding between the raters and the expert, which may need further clarification or training for the raters.

When investigating agreement between trained raters and an expert from video performances, @furtado2012 found 'excellent' and 'good' agreement between raters and an expert for 'Skip' (.77) and 'Jump' (.70), respectively, and 'excellent' agreement for 'Hop' (.85). It is important to note that the decision tree for "Jump' was modified following the @furtado2012 study and re-assessed recently [@furtado2018]. The agreement improved from .70 (good) to .88 (excellent). The lower kappa score (.73) observed in the current study for 'Jump' is likely due to rater variability and the source of observation, which in the current study was from live performance compared to video performance in the 2018 study.

A mean kappa value of .74 indicated an 'excellent' alignment between the raters and the expert in the MFMS category. The evaluations for the 'Throw' and 'Kick' skills aligned well with the expert's ratings, resulting in 'excellent' (.75) and 'good' (.73) agreement levels, respectively. The scores for 'Dribble' and 'Catch' had higher scores, with mean kappa values of .86 and .83, respectively. Like 'Jump', the decision trees for 'Dribble' and 'Catch' were modified following the @furtado2012 study and re-assessed in the @furtado2018 study. The kappa values improved from .72 (good) to .81 (excellent) and .72 (good) to .94 (excellent) for 'Dribble' and 'Catch', respectively. For the current study, 'Strike' displayed fair agreement (.51). In its initial assessment [@furtado2012], the kappa value for 'Strike' was .79. This value, however, significantly improved to .93 in a subsequent study [@furtado2018]. Similar to 'Skip', the differences in the kappa values for 'Strike' suggest that there may be discrepancies in how the raters and the expert interpret or understand the test's protocol or criteria, which may require additional clarification or training for the raters in future studies.

When looking at all eight FG-COMPASS skills, an average kappa value of .70 for the total test (TFMS) suggests a good agreement between the expert and the raters. The empirical findings highlight the significance of familiarizing oneself with the test protocol before utilizing the FG-COMPASS, particularly in skills where agreement with the expert was moderate (e.g., skip and strike).

# Conclusion

This study looked closely at the FG-COMPASS. It focused on how well it worked with the TGMD-2, how reliable it was between and within raters, and how much an expert and raters agreed. The results demonstrate promising evidence of the FG-COMPASS's applicability and robustness as a motor skill assessment tool. The assessment of concurrent validity with the TGMD-2 shows an excellent match between the two instruments. This shows that the FG-COMPASS could be a good alternative or supplementary tool. The 'good' agreement in the locomotor subtest calls for attention to specific nuances, which may be further explored in future studies. The evaluation of inter-rater reliability reveals 'good' agreement for LFMS, 'excellent' for MFMS, and 'good' for the overall test (TFMS). The discrepancies observed, especially with rater #5 for 'Throw', underline the importance of standardized interpretations and training among raters. The intra-rater reliability assessment, which explored consistency in live versus video assessments, indicates 'good' agreement. The variance in some skills, such as 'Jump', highlights the complexities of live assessment and warrants further examination. Finally, the analysis of agreement between raters and an expert emphasizes the significance of understanding and aligning with the test protocol. The agreement for LFMS was deemed 'good', while MFMS received an 'excellent' rating, resulting in an overall 'good' agreement. This reinforces the FG-COMPASS's ability to provide a strong agreement between FMS classifications from raters and a 'gold standard'.

## Implications and Future Directions

The findings collectively support the FG-COMPASS as a valuable instrument for motor skill assessment. The observed discrepancies in some areas provide constructive insights for refining the test, ensuring better alignment with established tests like the TGMD-2, and enhancing rater training and standardization. Future research should delve into the subtle differences in the locomotor subtest and seek to understand the variations in rater interpretations. Enhancing the FG-COMPASS through ongoing refinement and validation is important for more accurate and consistent motor skill evaluations in research and practical settings. This study contributes to the growing body of knowledge supporting FG-COMPASS's efficacy. It sets the stage for its broader implementation and potential impact on motor skill assessment.

# Limitations

Although precautions were taken, it's important to note that this study has some limitations. Compared to the TGMD-2, which consists of six locomotor and six manipulative skills, the FG-COMPASS has three locomotor and five manipulative skills. This discrepancy may have affected the alignment between the two tests, particularly in the locomotor subtest. Second, the discrepancies observed with certain raters, such as rater #5, may point to inconsistencies in rater training or interpretation of the criteria. This could affect the overall reliability of the ratings. Third, the variability in kappa values between raters and the expert for certain skills indicates potential differences in interpretation or understanding of the evaluation criteria. This may warrant further clarification or training. Fourth, due to the small sample size, there may be limitations in generalizing the findings to broader populations.

## Declaration of Conflicting Interest

The authors state that they have no conflicts of interest.

{{< pagebreak >}}

# References

<!-- References will auto-populate in the refs div below -->

::: {#refs}
:::

# Appendix

## Caption for Figure 1

Figure 1: The FG-COMPASS decision tree for the 'Overhand Throw' skill assessment. The tree starts with a primary decision node posing a question to differentiate between levels 1 and 4. Depending on the answer, the assessor is guided to subsequent nodes, simplifying the identification of proficiency levels down to two critical performance criteria, and ultimately leading to the end nodes representing the proficiency levels determined.

## Caption for Figure 2

Figure 2: Bland-Altman plot analyzing the LFMS subtest scores from the FG-COMPASS and the TGMD-2. The plot contrasts the mean of the scores (x-axis) against their differences (y-axis), with 95% limits of agreement highlighted.

## Caption for Figure 3

Figure 3: Bland-Altman plot analyzing the MFMS subtest scores from the FG-COMPASS and the TGMD-2. The plot contrasts the mean of the scores (x-axis) against their differences (y-axis), with 95% limits of agreement highlighted.

## Caption for Figure 4

Figure 4: Bland-Altman plot analyzing the TFMS subtest scores from the FG-COMPASS and the TGMD-2. The plot contrasts the mean of the scores (x-axis) against their differences (y-axis), with 95% limits of agreement highlighted.

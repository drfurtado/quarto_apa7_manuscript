\documentclass[
  man,
  colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue]{apa7}

% TODO: Add custom LaTeX header directives here
\makeatletter
\renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
	{0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
	{-.5em}%
	{\normalfont\normalsize\bfseries\typesectitle}}

\renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{0.5em}%
	{0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
	{-\z@\relax}%
	{\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
\makeatother

\makeatletter\@ifpackageloaded{caption}{}{\usepackage{caption}}\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}\makeatother\makeatletter\makeatother\makeatletter\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}\makeatother



% \usepackage[style=apa,backend=biber]{biblatex}
% % \addbibresource{bibliography.bib}
% 
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\title{Collecting Concurrent Validity, Expert-Rater Agreement, and
Inter/Intra-Rater Reliability for the FG-COMPASS}
\shorttitle{Validity and reliability of a test}




\authorsnames[{1},{2},{3}]{
Mackinsey Woolever,Ovande Furtado Jr,Jere D. Gallagher
}

\authorsaffiliations{
{Department of Kinesiology, California State University,
Northridge},{Department of Kinesiology, California State University,
Northridge},{University of Pittsburgh}}

\date{}
\abstract{Fundamental movement skills (FMS) are the building blocks for
developing specialized sports skills. In addition, fundamental movement
skill competency has been linked to decreased levels of obesity and
increased levels of physical activity/sports participation. This study
aimed to collect evidence for concurrent validity, inter-intra-, and
expert-rater reliability for the FG-COMPASS. Participants were 34
children ages 5-10 years. The agreement between the FG-COMPASS and
TGMD-2 was evaluated using the intraclass correlation coefficient (ICC)
and Bland-Altman analysis for LFMS, MFMS, and TFMS. The ICC for the LFMS
subtest was 0.68, indicating a `good' agreement between the two tests.
The Bland-Altman analysis revealed a mean bias close to zero.
`Excellent' agreement was observed for the MFMS subtest, with an ICC of
0.89 and Bland-Altman bias close to zero. The TFMS also demonstrated
`excellent' agreement, with an ICC of 0.89 and Bland-Altman bias close
to zero. The inter-rater reliability of the FG-COMPASS was assessed by
comparing the live scores of all five raters involved in the study.
Weighted kappa values ranged from 0.42 to 0.93 (M = 0.66, SD = .15) for
the LFMS subtest and from 0.31 to 0.93 (M = 0.77, SD = 0.15) for the
MFMS subtest. The test's combined score (TFMS) was 0.72 (SD = 0.15). The
resulting weighted kappa indicates `good' agreement for the LFMS, MFMS
subtests, and the total test (TFMS). The weighted kappa results for the
intra-rater reliability indicate a `good' agreement for LFMS (0.69),
MFMS (0.70), and TFMS (0.70). The agreement between raters and the
expert indicates a `good' agreement for LFMS (0.64), MFMS (0.75), and
TFMS (0.70). This study shows that the FG-COMPASS is a reliable and
effective tool for assessing motor skills. Future research should focus
on exploring any minor differences in the locomotor subtest and
understanding the variations in rater interpretations. Additionally,
adding two more skills to the locomotor subtest would be beneficial.}
% % \addbibresource{bibliography.bib}
% 
\keywords{Assessment, Fundamental Movement Skills, Children, Movement
Competence, Rating
Scales, Assessment, Reliability, Agreement, Concurrent Validity}

\authornote{\par{\addORCIDlink{Mackinsey
Woolever}{0000-0000-0000-0000}}\par{\addORCIDlink{Ovande Furtado
Jr}{0000-0003-3847-6314}}
\par{ Jere D. Gallagher is deceased.}
\par{        }
\par{Correspondence concerning this article should be addressed to Ovande
Furtado Jr, Department of Kinesiology, California State University,
Northridge, 18111 Nordhoff
St, Northridge, CA 91330-8287, Email: ovande@gmail.com (818-564-7507)}}


\begin{document}
\maketitle
The acquisition of fundamental movement skills (FMS) is critically
important for young children, as it can significantly influence their
development and lifestyle. Motor competence plays a pivotal role in an
individual's participation in physical activities (Castelli \& Valley,
2007). Studies have demonstrated a favorable correlation between
perceived motor competence and proficiency in FMS among children and
adolescents (Woods et al., 2007). Engagement in physical activity and
the development of FMS are positively correlated, particularly when the
activities are of moderate to vigorous intensity (Bellows et al., 2013;
Fisher et al., 2005; Lemos, 2012; McKenzie et al., 2002). Moreover,
there is an inverse relationship between physical activity involvement
and the prevalence of obesity (Bayer et al., 2009; Graf et al., 2004;
Lopes et al., 2012). Inadequate motor skill competence in children is
correlated with reduced physical activity levels (Fisher et al., 2005;
McKenzie et al., 2002) and an increased likelihood of being overweight
or obese (Cliff et al., 2012).

Assessing the development of FMS is crucial for preschool and primary
school children, as these skills significantly influence their overall
development and well-being. According to Ulrich (2000), early childhood
education often neglects the development of gross motor abilities.
Assessment instruments are developed to identify variations in motor
development, ranging from minor to significant delays. Failure to
promptly address delays in motor skill development may hinder the
subsequent development of gross motor skills (Ulrich, 2000) and affect
the acquisition of specialized skills (Gabbard, 2021).

As noted by Provost et al. (2000), a developmental delay is defined as a
discrepancy of 25\% or greater between a child's chronological age and
developmental age. Early detection of motor delays enables
practitioners, parents, and educators to implement effective
intervention measures. Various instruments exist for assessing FMS, as
highlighted by Cools et al. (2009). However, many of these tools are not
designed for live assessment by a single practitioner, typically
requiring performance recording and later evaluation. Developing an
assessment tool that allows professionals to assess children's FMS
proficiency in real-time without performance recording would enhance
convenience and efficiency.

The Furtado-Gallagher Children Observational Movement Pattern Assessment
System (FG-COMPASS) was developed to address the need for a practical
assessment tool to evaluate gross motor development in school-age
children, focusing on three performance criteria to evaluate FMS
performance (Furtado Jr \& Gallagher, 2012). To date, no studies have
compared the results of the FG-COMPASS with those of a criterion
measure. Although the FG-COMPASS has demonstrated evidence of both
inter- and intra-rater reliability, the agreement data used in these
studies were obtained through video analysis rather than live
performances (Furtado Jr \& Gallagher, 2012; Furtado \& Gallagher,
2018).

Collecting psychometric data on live performance is crucial, as the
FG-COMPASS is intended for use in real-time settings without the need
for video recording. Therefore, this study aimed to establish
criterion-related (concurrent) validity for the FG-COMPASS by comparing
its results with the TGMD-2 (Ulrich, 2000), a popular instrument for
assessing FMS in children. Additionally, this study sought to gather
further evidence of inter-, intra-, and expert-rater\footnote{The
  co-author of the FG-COMPASS served as the expert in this study.}
reliability for the FG-COMPASS through live assessments.

Several hypotheses were proposed for this study. We anticipated that
there would be at least a `good' agreement (ICC/kappa scores above 0.74)
for the locomotor (LFMS), manipulative (MFMS), and total test (TFMS)
components when investigating concurrent validity, inter- and
intra-rater reliability, and expert-rater reliability for the
FG-COMPASS.

\section{Materials and Methods}\label{materials-and-methods}

\subsection{Participants}\label{participants}

A convenient sampling method was employed to recruit participants for
this study. Following Institutional Review Board approval from
(XXXXXXX), 41 children between the ages of 5 and 10 were initially
recruited. Ultimately, 34 children, comprising 22 girls (\emph{M} =
8.14, \emph{SD} = 1.78) and 12 boys (\emph{M} = 8.44, \emph{SD} = 1.49),
fully participated. Three participants independently withdrew from the
study; two did not attend the assessment sessions, one was injured prior
to the assessment, and one child relocated out of state during the data
collection period. Informed consent was obtained from the parents or
legal guardians of all participants prior to their involvement in the
study and the children assent to participate.

To ensure an even distribution of age ranges, one randomly selected
classroom from kindergarten through fourth grade received a recruitment
packet. If no consent forms were returned, recruitment packets were
distributed to additional classrooms. Participants were excluded from
the study if they met any of the following criteria: 1) younger than
five years or older than 10 years and 11 months; 2) had developmental
delays or disabilities that could affect motor performance; 3) lacked
parental or verbal consent ; or 4) had a ``yes'' response on any of the
first five Physical Activity Readiness-Questionnaire (PAR-Q) questions
(Adams, 1999).

\subsection{Measures}\label{measures}

\subsubsection{TGMD-2}\label{tgmd-2}

The TGMD-2 (Ulrich, 2000) served as the gold standard for the concurrent
validity analysis. This instrument evaluates twelve gross motor skills,
divided into two categories: six concerning locomotion and six related
to object manipulation, suitable for children aged 3 to 10 years. The
TGMD-2 assesses various performance criteria focusing on different body
components, including the arms, legs, and trunk. For example, one
criterion for hopping is that the ``arms be flexed and swing forward to
generate force.'' Each child is given two attempts to demonstrate each
skill; successful attempts are awarded a score of 1, while unsuccessful
attempts receive a score of 0. After two trials for each skill, the
scores are totaled to obtain the overall raw score for each subtest.
These raw scores are then converted to standard scores, enabling
comparison to normative data. Researchers can determine age equivalents
and percentiles by analyzing the standard scores from both subtests.
These standard scores, when combined, form a gross motor quotient value.

Several studies have addressed the validity and reliability of the
TGMD-2. The instrument demonstrates strong construct validity,
effectively measuring the fundamental theoretical construct of gross
motor development (Ulrich, 2000). Its concurrent validity is supported
through correlations with other established motor skill assessments,
such as the Movement Assessment Battery for Children (MABC) (Cools et
al., 2009). High test-retest reliability of the TGMD-2 has been
reported, with coefficients frequently exceeding 0.90 (Valentini \&
Rudisill, 2004). The test maintains good internal consistency, evidenced
by Cronbach's alpha values generally above 0.80 for both the locomotion
and object manipulation subtests (Wiart \& Darrah, 2001). The TGMD-2 has
also been adapted and validated in different cultural contexts,
indicating its utility across various populations (Barnett et al.,
2009). The standardization process involved a representative sample of
children in the United States, ensuring the relevance of the normative
data for the target age group.

\subsubsection{FG-COMPASS}\label{fg-compass}

The FG-COMPASS is a tool created to assess the gross motor skills of
children aged 5 to 10 years. It evaluates eight skills, including three
related to locomotion and five to object manipulation. In the
development of FG-COMPASS, Furtado Jr and Gallagher (2012) introduced a
novel approach to constructing FMS rating scales. This method, detailed
further in works by Perez (2018) and Furtado Jr and Gallagher (2012),
utilizes key performance criteria arranged in a decision tree. Figure 1
depicts the decision tree for the `Overhand Throw' skill, demonstrating
three types of nodes: decision nodes, which pose questions; chance
nodes, offering `yes or no' options; and end nodes, which indicate
proficiency levels.

Despite the availability of numerous performance criteria for each
skill, only three are selected to create the decision tree. These trees
are formed through questions derived from the criteria. For instance, in
Figure 1, a question at the top decision node aims to differentiate
between levels 1 and 4. A `yes' at the chance node directs to the right
pathway, prompting a follow-up question to confirm if the individual
exhibits a level 4 proficiency in overhand throws. If the answer is
`no,' the rating settles at level 3.

A similar process occurs on the left side of the tree to assess for
level 1 proficiency. This approach allows for a simplified evaluation of
live performances of FMS, restricting the assessment to just two
performance criteria when determining skill proficiency levels. The
FG-COMPASS enjoys support from several studies validating its efficacy
and reliability, including evidence for content-related validity
(Furtado, 2004), expert-rater agreement (Furtado Jr \& Gallagher, 2012;
Furtado \& Gallagher, 2018), and intra- and inter-rater reliability
{[}Furtado and Gallagher (2018){]} from video performances.

{[}figure 1 here{]}

\subsection{Research Assistants}\label{research-assistants}

Sixteen undergraduate kinesiology students were selected as research
assistants for this study. Ten students were chosen to serve as raters
in the assessment of gross motor skills, with a random assignment of
five raters per instrument: TGMD-2 and FG-COMPASS. The remaining
students were assigned roles as test administrators---three for TGMD-2
and two for FG-COMPASS---except for one individual assigned to edit
videos remotely, thus not requiring presence at the research site.

Before initiating data collection, all participants underwent training
tailored to their designated roles and respective instruments. The
training involved multiple sessions designed to equip them with the
necessary skills, including instruction on setting up for skills
assessment, accurately demonstrating tasks, and appropriately using and
positioning cameras for recording. This comprehensive training ensured
that both raters and test administrators were well-prepared to carry out
their tasks effectively during the data collection phase.

\subsection{Procedures}\label{procedures}

\subsubsection{Data collection}\label{data-collection}

The TGMD-2 and the FG-COMPASS, while assessing the same construct,
differ in their evaluation methods. Despite these differences, common
procedures were followed in administering both tests. The assessments
were conducted during morning or lunch recess periods to ensure all
student participants could complete both tests.

Before data collection began, the primary investigator assigned
identification numbers to the participants to maintain organization.
Upon arrival at the test location, participants were guided to either
the TGMD-2 or FG-COMPASS stations according to a randomized list. This
setup was revisited weekly to mitigate potential learning effects from
repeated measurements of the same skill. After completing the initial
test at one station, participants moved to the alternate station for
further assessment. In some cases, participants demonstrated multiple
skills across both stations, alternating between them as needed.

The administrators overseeing the TGMD-2 station conducted assessments
weekly, following the directives detailed in the user manual by Ulrich
(2000). All skill performances were videotaped, and TGMD-2 raters later
assessed the performances in the lab using the recorded videos. The
FG-COMPASS raters evaluated participants directly on-site, although
these performances were also recorded for intra-rater reliability
analysis. Participants were provided one practice trial and three test
trials for each skill.

\subsection{Data Analysis}\label{data-analysis}

Concurrent validity was assessed using the intraclass correlation
coefficient (ICC, 2, k) and Bland-Altman plots. The reliability of the
FG-COMPASS, both in terms of inter- and intra-rater consistency and the
agreement between the expert and raters, was examined using weighted
kappa statistics.

The ICC is designed to evaluate the reliability of ratings by comparing
the variation of different ratings for the same participant to the total
variation across all ratings and participants (McGraw \& Wong, 1996).
The Bland-Altman method involves determining the agreement between two
quantitative measurements by studying the average difference and setting
agreement limits, a strategy preferred over correlation techniques
(Bland \& Altman, 1986; Giavarina, 2015).

The weighted kappa index is recommended when more than two coders
independently classify an entity into three or more categories at an
ordinal level, assigning different weights based on the degree of
disagreement (Fleiss \& Cohen, 1973). Unlike kappa, the weighted version
considers the degree of disagreement in its calculation. The
interpretation of weighted kappa and ICC values followed this scheme:
above 0.75 indicated excellent agreement; values between 0.74 and 0.60
were good; values between 0.59 and 0.40 were fair, and values below 0.40
were poor (Cicchetti, 1994).

A cross-sectional design was utilized in this study, and all statistical
analyses were conducted using the statistical package jamovi (The jamovi
project, 2022).

\section{Results}\label{results}

\subsection{Concurrent Validity}\label{concurrent-validity}

The agreement between the FG-COMPASS and TGMD-2 was evaluated using the
intraclass correlation coefficient (ICC) and Bland-Altman analysis for
the locomotor (LFMS), manipulative (MFMS), and total fundamental
movement skills (TFMS) subtests (see \{tbl-table1\}).

The ICC for the LFMS subtest was 0.68, indicating `good' agreement
between the two tests. The Bland-Altman analysis for the LFMS subtest
revealed a mean bias close to zero (see Figure 2).

The MFMS subtest exhibited `excellent' agreement, with an ICC of 0.89
and Bland-Altman bias also close to zero (see Figure 3).

Similarly, the TFMS subtest demonstrated `excellent' agreement, with an
ICC of 0.89 and Bland-Altman bias close to zero (see Figure 4).

\phantomsection\label{tbl-table1}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.2093}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1279}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.2674}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1395}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1279}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1279}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
ICC
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
F-Statistic (p-value)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Bias
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
LLA
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
ULA
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Locomotor} & 0.68 & 3.05 (*) & 1.73e−16 & −1.95 & 1.95 \\
\textbf{Manipulative} & 0.89 & 8.85 (**) & 2.60e−16 & −1.25 & 1.25 \\
\textbf{Total test} & 0.89 & 9.00 (**) & −2.53e−16 & −1.24 & 1.24 \\
\end{longtable}

{[}figure 2 here{]} {[}figure 3 here{]} {[}figure 4 here{]}

\subsection{Inter-Rater Reliability}\label{inter-rater-reliability}

The inter-rater reliability of the FG-COMPASS was assessed by comparing
the live scores of all five raters involved in the study (see
Table~\ref{apatb-table2}). Weighted kappa values were computed for each
pair of raters, and then the mean was calculated to provide a single
index of reliability (Light, 1971). Weighted kappa values ranged from
0.42 to 0.93 (M = 0.66 SD = .15) for the LFMS subtest and from 0.31 to
0.93 (M = 0.77 SD = 0.15) for the MFMS subtest. The test's combined
score (TFMS) was 0.72 (SD = 0.15). The resulting weighted kappa
indicates `good' agreement for the LFMS, MFMS subtests, and the total
test (TFMS).

\begin{table}
\caption{Weighted Kappa Statistics for the Inter-Rater Analysis}
\label{apatb-table2}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 26\tabcolsep) * \real{0.1471}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 26\tabcolsep) * \real{0.1471}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 26\tabcolsep) * \real{0.0588}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 26\tabcolsep) * \real{0.0588}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 26\tabcolsep) * \real{0.0588}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 26\tabcolsep) * \real{0.0588}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 26\tabcolsep) * \real{0.0588}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 26\tabcolsep) * \real{0.0588}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 26\tabcolsep) * \real{0.0588}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 26\tabcolsep) * \real{0.0588}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 26\tabcolsep) * \real{0.0588}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 26\tabcolsep) * \real{0.0588}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 26\tabcolsep) * \real{0.0588}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 26\tabcolsep) * \real{0.0588}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Skill
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
1x2
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
1x3
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
1x4
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
1x5
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
2x3
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
2x4
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
2x5
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
3x4
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
3x5
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
4x5
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Mean
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
SD
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{LFMS} & & & & & & & & & & & & \textbf{.66} & .15 \\
& Hop & .56 & .43 & .43 & .50 & .42 & .49 & .46 & .53 & .64 & .52 & .50
& .07 \\
& Jump & .93 & .91 & .70 & .65 & .84 & .73 & .62 & .61 & .61 & .69 & .73
& .12 \\
& Skip & .78 & .74 & .60 & .63 & .87 & .77 & .76 & .69 & .71 & .83 & .74
& .08 \\
\textbf{MFMS} & & & & & & & & & & & & \textbf{.77} & .15 \\
& Throw & .85 & .79 & .85 & .45* & .80 & .73 & .35* & .71 & .31* & .40*
& .62 & .22 \\
& Kick & .83 & .68 & .64 & .82 & .63 & .59 & .73 & .50 & .72 & .64 & .68
& .10 \\
& Dribble & .86 & .87 & .83 & .92 & .88 & .84 & .91 & .88 & .93 & .93 &
.89 & .04 \\
& Catch & .87 & .91 & .87 & .90 & .83 & .84 & .90 & .80 & .80 & .89 &
.86 & .04 \\
& Strike & .81 & .80 & .72 & .72 & .87 & .80 & .80 & .69 & .78 & .79 &
.78 & .05 \\
\textbf{TFMS} & & & & & & & & & & & & \textbf{.72} & .15 \\
\end{longtable}

\tablenote{LFMS:\ Locomotor Subtest. MFMS:\ Manipulative Subtest. TFMS:\ Locomotor and Manipulative scores combined. <br/> Asterisks indicate major disagreement between rater 5 and all other raters.}

\end{table}

\subsection{Intra-rater reliability for the
FG-COMPASS}\label{intra-rater-reliability-for-the-fg-compass}

We evaluated the consistency of ratings by comparing live assessments
with those obtained through video assessments (see
Table~\ref{apatb-table3}). Of particular interest is `IR1', which
compares the ratings obtained from live assessments with those from
recorded performances (time 1), which took place one week after the live
assessment at the site. Additionally, we included ratings from a second
video assessment and compared it with the live assessment (IR2) and the
first video assessment (IR3). Table~\ref{apatb-table4} provides the mean
and standard deviation scores for each intra-rater comparison across all
five raters. Scores ranged from 0.50 to 0.89, indicating agreement from
`fair' to `excellent' (Cicchetti, 1994).

\newpage{}

\begin{table}
\caption{Intra-Rater Agreement Measured by Weighted Kappa Coefficients Across Different Skills}
\label{apatb-table3}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 30\tabcolsep) * \real{0.0441}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 30\tabcolsep) * \real{0.0637}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 30\tabcolsep) * \real{0.0637}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 30\tabcolsep) * \real{0.0637}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 30\tabcolsep) * \real{0.0637}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 30\tabcolsep) * \real{0.0637}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 30\tabcolsep) * \real{0.0637}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 30\tabcolsep) * \real{0.0637}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 30\tabcolsep) * \real{0.0637}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 30\tabcolsep) * \real{0.0637}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 30\tabcolsep) * \real{0.0637}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 30\tabcolsep) * \real{0.0637}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 30\tabcolsep) * \real{0.0637}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 30\tabcolsep) * \real{0.0637}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 30\tabcolsep) * \real{0.0637}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 30\tabcolsep) * \real{0.0637}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Rater 1
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Rater 2
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Rater 3
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Rater 4
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Rater 5
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
& IR1 & IR2 & IR3 & IR1 & IR2 & IR3 & IR1 & IR2 & IR3 & IR1 & IR2 & IR3
& IR1 & IR2 & IR3 \\
Hop (17) & 0.72 & 0.83 & 0.89 & 0.44 & 0.55 & 0.75 & 0.64 & 0.62 & 0.88
& 0.69 & 0.40 & 0.62 & 0.84 & 0.62 & 0.80 \\
Jump (18) & 0.56 & 0.49 & 0.83 & 0.46 & 0.68 & 0.39 & 0.74 & 0.38 & 0.49
& 0.56 & 0.28 & 0.56 & 0.67 & 0.67 & 1.00 \\
Skip (18) & 0.96 & 0.96 & 1.00 & 0.94 & 0.78 & 0.86 & 0.92 & 0.86 & 0.89
& 0.51 & 0.68 & 0.86 & 0.66 & 0.52 & 0.83 \\
Throw (18) & 0.80 & 0.52 & 0.53 & 0.63 & 0.62 & 0.97 & 0.52 & 0.54 &
0.60 & 0.69 & 0.76 & 0.70 & 0.54 & 0.66 & 0.86 \\
Kick (19) & 0.72 & 0.68 & 0.78 & 0.66 & 0.60 & 0.76 & 0.80 & 0.70 & 0.74
& 0.74 & 0.64 & 0.72 & 0.64 & 0.62 & 0.80 \\
Dribble (17) & 0.86 & 0.80 & 0.82 & 0.70 & 0.78 & 0.86 & 0.66 & 0.60 &
0.82 & 0.76 & 0.68 & 0.74 & 0.60 & 0.64 & 0.68 \\
Catch (20) & 0.68 & 0.62 & 0.86 & 0.86 & 0.66 & 0.80 & 0.76 & 0.78 &
0.82 & 0.66 & 0.60 & 0.78 & 0.84 & 0.88 & 0.88 \\
Strike (20) & 0.62 & 0.56 & 0.60 & 0.74 & 0.70 & 0.70 & 0.64 & 0.64 &
0.64 & 0.74 & 0.68 & 0.68 & 0.70 & 0.62 & 0.78 \\
\end{longtable}

\tablenote{Quadratic weighted kappa values range from -1 to 1. IR1, IR2, and IR3 represent three different comparison pairs:\ IR1 compares the ratings from the live performances with the recorded video (time 1), IR2 compares ratings from the live performances with the recorded video (time 2), and IR3 compares the ratings from the recorded performances from time 1 and time 2. Sample sizes for each skill are provided in parentheses next to the skill name. Rater 1 to Rater 5 represents five different individuals who rated the performances.}

\end{table}

\newpage{}

\begin{table}
\caption{Summary of Quadratic Weighted Kappa for Intra-Rater Comparisons Across Motor Skills}
\label{apatb-table4}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Skill & IR1 Mean (SD) & IR2 Mean (SD) & IR3 Mean (SD) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
LFMS & \textbf{0.69} & 0.62 & 0.78 \\
Hop & 0.67 (0.13) & 0.60 (0.14) & 0.79 (0.10) \\
Jump & 0.60 (0.10) & 0.50 (0.16) & 0.65 (0.23) \\
Skip & 0.80 (0.18) & 0.76 (0.15) & 0.89 (0.06) \\
MFMS & \textbf{0.70} & 0.66 & 0.76 \\
Throw & 0.64 (0.10) & 0.62 (0.09) & 0.73 (0.16) \\
Kick & 0.71 (0.06) & 0.65 (0.04) & 0.76 (0.03) \\
Dribble & 0.72 (0.09) & 0.70 (0.08) & 0.78 (0.06) \\
Catch & 0.76 (0.08) & 0.71 (0.11) & 0.83 (0.04) \\
Strike & 0.69 (0.05) & 0.64 (0.05) & 0.68 (0.06) \\
TFMS & \textbf{0.70} & 0.64 & 0.77 \\
\end{longtable}

\tablenote{IR1, IR2, IR3:\ Represent different inter-rater comparisons (e.g., live vs. video 1, live vs. video 2, video 1 vs. video 2). Mean:\ The average of the quadratic weighted kappa values for each scenario across all raters and skills. SD:\ The standard deviation of the quadratic weighted kappa values for each scenario across all raters and skills.}

\end{table}

\subsection{Expert-Rater Agreement for the
FG-COMPASS}\label{expert-rater-agreement-for-the-fg-compass}

The study aimed to assess the level of agreement between raters and
expert ratings for the FG-COMPASS. The live ratings of five raters were
compared with the expert's video scores. The results showed that the
level of agreement varied across the skills assessed. For `Hop', the
agreement ranged from `fair' to `excellent', with a mean kappa value of
0.67. The agreement was more varied for' Skip', with kappa values
ranging from `poor' to `excellent'. In the MFMS subtest, the agreement
was considered `excellent'. For `Throw', the agreement ranged from good
to excellent, with a mean kappa value of 0.75. For `Dribble', all raters
showed `excellent' agreement, with kappa values ranging from 0.77 to
0.94 and a mean kappa of 0.86. For `Catch', the agreement was
`excellent', with a mean kappa value of 0.83. For `Strike', the
agreement was `fair' to `good' with kappa values ranging from 0.40 to
0.61 and a mean kappa of 0.51. Considering all skills (TFMS), the mean
kappa value was 0.70, indicating `good' agreement across all skills when
considering all raters.

